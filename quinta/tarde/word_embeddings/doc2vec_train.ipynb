{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import gensim.models as g\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#doc2vec parameters\n",
    "vector_size = 300\n",
    "window_size = 25 #15\n",
    "min_count = 1\n",
    "sampling_threshold = 1e-5\n",
    "negative_size = 5\n",
    "train_epoch = 200 #100\n",
    "dm = 0 #0 = dbow; 1 = dmpv\n",
    "worker_count = 1 #number of parallel processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#pretrained word embeddings\n",
    "pretrained_emb = \"toy_data/pretrained_word_embeddings.txt\" #None if use without pretrained embeddings\n",
    "\n",
    "#input corpus\n",
    "train_corpus = \"toy_data/sinopses.txt\" #train_docs\n",
    "\n",
    "#output model\n",
    "saved_path = \"toy_data/model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#def read_corpus(fname, tokens_only=False):\n",
    "    #with open(fname) as f: #\n",
    "        #read_data = f.readlines()\n",
    "        #for i, line in enumerate(read_data):\n",
    "            #t_corpus = line.split(\" | \")\n",
    "            #if(len(t_corpus)==2):\n",
    "                # For training data, add tags\n",
    "                #yield g.doc2vec.TaggedDocument(t_corpus[1], [i])\n",
    "            #yield g.doc2vec.TaggedDocument(line, [i])\n",
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.tokenize import word_tokenize\n",
    "            \n",
    "def read_corpus(fname, tokens_only=False): \n",
    "    with open(fname) as f: #\n",
    "        read_data = f.readlines()\n",
    "        for i, line in enumerate(read_data):\n",
    "            t_corpus = line.split(\" | \")\n",
    "            if(len(t_corpus)==2):\n",
    "                #corpus_tokenized = word_tokenize(t_corpus[1])\n",
    "                #text = nltk.Text(corpus_tokenized)\n",
    "                #print('text: ', text)\n",
    "                #removing stopwords\n",
    "                #filtered_words = [word for word in corpus_tokenized if word not in stopwords.words('portuguese')]\n",
    "                #print(filtered_words)\n",
    "                # For training data, add tags\n",
    "                #train_docs =  list(g.doc2vec.TaggedDocument(t_corpus[1], [i]))\n",
    "                yield g.doc2vec.TaggedDocument(t_corpus[1], [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_docs = list(read_corpus(train_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words='As coisas estavam mal para a Inteligência Britânica, pois a Smersh começara a sabotar a estabilidade global: nada menos do que onze agentes foram abatidos e, para piorar as coisas, seu maior agente secreto, o 007, estava desfrutando de sua aposentadoria. Sir James Bond, o primeiro 007, é convencido por alguns chefes de agências de espionagem a combater o inimigo comum. Essa versão de \"Cassino Royale\" não é uma versão oficial dos filmes de 007, pois foi rodado por outra equipe, estúdios, fora dos padrões e contratos. É uma produção anglo-americana de 1967, do gênero comédia de espionagem.\\n', tags=[0]),\n",
       " TaggedDocument(words='A ação é eletrizante e ininterrupta, pois o agente 007 (Sean Connery) vai além do dever do ofício e até as profundezas do oceano para encontrar um perigoso criminoso que está ameaçando milhões de pessoas através da chantagem de destruir o mundo por meio de um holocausto nuclear.\\n', tags=[1]),\n",
       " TaggedDocument(words='Com a queda da Cortina de Ferro e o final da Guerra Fria, o modo de obter poder deu ao mundo uma nova ordem, que envolvem esquemas perigosos que visam apenas o lucro. Neste contexto, James Bond (Pierce Brosnan) conhece em Mônaco Xenia Onatopp (Famke Janssen), uma mulher extremamente bela e perigosamente mortal, que pertence a Máfia russa. Bond tenta encontrar o Goldeneye, uma arma secreta espacial que destrói tudo que tenha um circuito eletrônico e que, caso caia em mãos erradas dará aos seus donos o poder de derrubar governos. Para impedir um catástrofe mundial, James se une a Natalya Simonova (Izabella Scorupco), uma programadora de computadores.\\n', tags=[2]),\n",
       " TaggedDocument(words='Desde a explosiva abertura até a fuga no último minuto no jatinho pessoal do Presidente, esta terceira aventura de James Bond é ágil e excitante! Sean Connery encarna novamente o Agente 007 e tem que enfrentar um vilão maníaco determinado a destruir todo o ouro de Fort Knox e a acabar com a economia mundial!\\n', tags=[3]),\n",
       " TaggedDocument(words='No filme que lançou a saga de James Bond, o Agente 007 (Sean Connery), tem que enfrentar o misterioso Dr. No, um cientista gênio determinado a destruir o programa espacial norte-americano. Correndo contra a contagem regressiva para o desastre, Bond precisa viajar para Jamaica, onde ele encontra a linda Honey Ryder (Ursula Andress) e confronta o vilão megalomaníaco em sua ilha fortaleza.\\n', tags=[4])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_docs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#enable logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = g.doc2vec.Doc2Vec(size=vector_size, window=window_size, min_count=min_count, sample=sampling_threshold, workers=worker_count, hs=0, dm=dm, negative=negative_size, dbow_words=1, dm_concat=1, iter=train_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-24 18:37:41,455 : INFO : collecting all words and their counts\n",
      "2018-01-24 18:37:41,461 : WARNING : Each 'words' should be a list of words (usually unicode strings). First 'words' here is instead plain <class 'str'>.\n",
      "2018-01-24 18:37:41,471 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-01-24 18:37:41,751 : INFO : collected 157 word types and 7771 unique tags from a corpus of 7529 examples and 2793992 words\n",
      "2018-01-24 18:37:41,751 : INFO : Loading a fresh vocabulary\n",
      "2018-01-24 18:37:41,752 : INFO : min_count=1 retains 157 unique words (100% of original 157, drops 0)\n",
      "2018-01-24 18:37:41,753 : INFO : min_count=1 leaves 2793992 word corpus (100% of original 2793992, drops 0)\n",
      "2018-01-24 18:37:41,754 : INFO : deleting the raw counts dictionary of 157 items\n",
      "2018-01-24 18:37:41,755 : INFO : sample=1e-05 downsamples 94 most-common words\n",
      "2018-01-24 18:37:41,756 : INFO : downsampling leaves estimated 57975 word corpus (2.1% of prior 2793992)\n",
      "2018-01-24 18:37:41,757 : INFO : estimated required memory for 157 words and 300 dimensions: 9780500 bytes\n",
      "2018-01-24 18:37:41,758 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-24 18:37:54,620 : INFO : training model with 1 workers on 158 vocabulary and 300 features, using sg=1 hs=0 sample=1e-05 negative=5 window=25\n",
      "2018-01-24 18:37:55,649 : INFO : PROGRESS: at 0.62% examples, 81369 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:37:56,649 : INFO : PROGRESS: at 1.32% examples, 86446 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:37:57,651 : INFO : PROGRESS: at 2.02% examples, 88114 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:37:58,653 : INFO : PROGRESS: at 2.72% examples, 89059 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:37:59,655 : INFO : PROGRESS: at 3.36% examples, 88014 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:00,657 : INFO : PROGRESS: at 4.07% examples, 88733 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:01,658 : INFO : PROGRESS: at 4.79% examples, 89372 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:02,660 : INFO : PROGRESS: at 5.49% examples, 89753 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:03,662 : INFO : PROGRESS: at 6.19% examples, 89993 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:04,663 : INFO : PROGRESS: at 6.89% examples, 90084 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:05,665 : INFO : PROGRESS: at 7.60% examples, 90331 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:06,666 : INFO : PROGRESS: at 8.31% examples, 90488 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:07,668 : INFO : PROGRESS: at 9.02% examples, 90699 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:08,669 : INFO : PROGRESS: at 9.72% examples, 90780 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:09,671 : INFO : PROGRESS: at 10.41% examples, 90758 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:10,671 : INFO : PROGRESS: at 11.06% examples, 90438 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:11,672 : INFO : PROGRESS: at 11.75% examples, 90403 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:12,673 : INFO : PROGRESS: at 12.46% examples, 90477 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:13,675 : INFO : PROGRESS: at 13.12% examples, 90293 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:14,677 : INFO : PROGRESS: at 13.81% examples, 90237 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:15,678 : INFO : PROGRESS: at 14.47% examples, 90063 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:16,679 : INFO : PROGRESS: at 15.00% examples, 89122 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:17,679 : INFO : PROGRESS: at 15.68% examples, 89166 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:18,680 : INFO : PROGRESS: at 16.31% examples, 88838 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:19,680 : INFO : PROGRESS: at 17.00% examples, 88948 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:20,682 : INFO : PROGRESS: at 17.73% examples, 89148 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:21,684 : INFO : PROGRESS: at 18.44% examples, 89316 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:22,685 : INFO : PROGRESS: at 19.15% examples, 89455 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:23,686 : INFO : PROGRESS: at 19.87% examples, 89599 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:24,687 : INFO : PROGRESS: at 20.57% examples, 89709 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:25,688 : INFO : PROGRESS: at 21.29% examples, 89829 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:26,689 : INFO : PROGRESS: at 21.99% examples, 89881 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:27,690 : INFO : PROGRESS: at 22.69% examples, 89938 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:28,692 : INFO : PROGRESS: at 23.38% examples, 89918 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:29,692 : INFO : PROGRESS: at 24.06% examples, 89930 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:30,693 : INFO : PROGRESS: at 24.76% examples, 89925 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:31,694 : INFO : PROGRESS: at 25.31% examples, 89456 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:32,694 : INFO : PROGRESS: at 26.01% examples, 89516 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:33,697 : INFO : PROGRESS: at 26.65% examples, 89366 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:34,698 : INFO : PROGRESS: at 27.36% examples, 89459 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:35,699 : INFO : PROGRESS: at 28.07% examples, 89549 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:36,700 : INFO : PROGRESS: at 28.78% examples, 89618 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:37,700 : INFO : PROGRESS: at 29.48% examples, 89681 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:38,702 : INFO : PROGRESS: at 30.18% examples, 89744 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:39,703 : INFO : PROGRESS: at 30.89% examples, 89797 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:40,705 : INFO : PROGRESS: at 31.59% examples, 89850 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:41,706 : INFO : PROGRESS: at 32.31% examples, 89922 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:42,708 : INFO : PROGRESS: at 33.01% examples, 89978 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:43,710 : INFO : PROGRESS: at 33.72% examples, 90016 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:44,711 : INFO : PROGRESS: at 34.42% examples, 90064 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:45,712 : INFO : PROGRESS: at 35.13% examples, 90104 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:46,713 : INFO : PROGRESS: at 35.84% examples, 90162 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:47,714 : INFO : PROGRESS: at 36.55% examples, 90208 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:48,717 : INFO : PROGRESS: at 37.26% examples, 90257 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:49,717 : INFO : PROGRESS: at 37.97% examples, 90303 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:50,719 : INFO : PROGRESS: at 38.68% examples, 90348 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:51,719 : INFO : PROGRESS: at 39.39% examples, 90391 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:52,722 : INFO : PROGRESS: at 40.09% examples, 90416 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:53,723 : INFO : PROGRESS: at 40.80% examples, 90457 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:54,724 : INFO : PROGRESS: at 41.51% examples, 90499 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:55,725 : INFO : PROGRESS: at 42.23% examples, 90541 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:56,727 : INFO : PROGRESS: at 42.93% examples, 90578 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:38:57,728 : INFO : PROGRESS: at 43.64% examples, 90598 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:58,730 : INFO : PROGRESS: at 44.35% examples, 90641 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:38:59,731 : INFO : PROGRESS: at 45.06% examples, 90674 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:00,734 : INFO : PROGRESS: at 45.76% examples, 90686 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:01,735 : INFO : PROGRESS: at 46.45% examples, 90689 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:02,737 : INFO : PROGRESS: at 47.16% examples, 90706 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:03,737 : INFO : PROGRESS: at 47.86% examples, 90719 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:04,739 : INFO : PROGRESS: at 48.56% examples, 90746 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:05,739 : INFO : PROGRESS: at 49.27% examples, 90768 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:06,740 : INFO : PROGRESS: at 49.98% examples, 90797 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:07,740 : INFO : PROGRESS: at 50.69% examples, 90813 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:08,741 : INFO : PROGRESS: at 51.40% examples, 90838 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:09,742 : INFO : PROGRESS: at 52.11% examples, 90865 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:10,744 : INFO : PROGRESS: at 52.82% examples, 90894 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:11,746 : INFO : PROGRESS: at 53.52% examples, 90915 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:12,746 : INFO : PROGRESS: at 54.23% examples, 90941 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:13,747 : INFO : PROGRESS: at 54.94% examples, 90966 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:14,749 : INFO : PROGRESS: at 55.64% examples, 90974 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:15,750 : INFO : PROGRESS: at 56.35% examples, 90993 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:16,753 : INFO : PROGRESS: at 57.05% examples, 91011 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:17,753 : INFO : PROGRESS: at 57.76% examples, 91028 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:18,754 : INFO : PROGRESS: at 58.46% examples, 91049 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:19,756 : INFO : PROGRESS: at 59.16% examples, 91067 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:20,756 : INFO : PROGRESS: at 59.88% examples, 91086 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:21,758 : INFO : PROGRESS: at 60.58% examples, 91107 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:22,761 : INFO : PROGRESS: at 61.30% examples, 91123 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:23,762 : INFO : PROGRESS: at 62.01% examples, 91141 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:24,764 : INFO : PROGRESS: at 62.72% examples, 91160 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:25,764 : INFO : PROGRESS: at 63.42% examples, 91176 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:26,765 : INFO : PROGRESS: at 64.13% examples, 91193 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:27,766 : INFO : PROGRESS: at 64.84% examples, 91208 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:28,767 : INFO : PROGRESS: at 65.55% examples, 91223 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:29,769 : INFO : PROGRESS: at 66.26% examples, 91237 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:30,769 : INFO : PROGRESS: at 66.95% examples, 91230 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:31,770 : INFO : PROGRESS: at 67.66% examples, 91239 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:32,770 : INFO : PROGRESS: at 68.37% examples, 91260 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:33,770 : INFO : PROGRESS: at 69.07% examples, 91269 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:34,770 : INFO : PROGRESS: at 69.78% examples, 91276 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:35,771 : INFO : PROGRESS: at 70.48% examples, 91284 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:36,771 : INFO : PROGRESS: at 71.18% examples, 91297 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:37,772 : INFO : PROGRESS: at 71.89% examples, 91308 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:38,773 : INFO : PROGRESS: at 72.60% examples, 91322 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:39,773 : INFO : PROGRESS: at 73.31% examples, 91341 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:40,776 : INFO : PROGRESS: at 74.02% examples, 91356 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:41,777 : INFO : PROGRESS: at 74.74% examples, 91373 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:42,778 : INFO : PROGRESS: at 75.45% examples, 91388 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:43,779 : INFO : PROGRESS: at 76.15% examples, 91396 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:44,779 : INFO : PROGRESS: at 76.87% examples, 91405 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:45,780 : INFO : PROGRESS: at 77.57% examples, 91419 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:46,781 : INFO : PROGRESS: at 78.29% examples, 91439 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:47,783 : INFO : PROGRESS: at 78.99% examples, 91451 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:48,784 : INFO : PROGRESS: at 79.70% examples, 91458 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:49,784 : INFO : PROGRESS: at 80.41% examples, 91467 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:50,786 : INFO : PROGRESS: at 81.12% examples, 91474 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:51,787 : INFO : PROGRESS: at 81.83% examples, 91485 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:52,789 : INFO : PROGRESS: at 82.54% examples, 91499 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:53,790 : INFO : PROGRESS: at 83.26% examples, 91509 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:54,791 : INFO : PROGRESS: at 83.96% examples, 91517 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:55,792 : INFO : PROGRESS: at 84.67% examples, 91527 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:56,794 : INFO : PROGRESS: at 85.39% examples, 91543 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:39:57,795 : INFO : PROGRESS: at 86.09% examples, 91555 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:58,796 : INFO : PROGRESS: at 86.80% examples, 91561 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:39:59,796 : INFO : PROGRESS: at 87.51% examples, 91569 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:40:00,798 : INFO : PROGRESS: at 88.22% examples, 91579 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:40:01,799 : INFO : PROGRESS: at 88.93% examples, 91590 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:40:02,799 : INFO : PROGRESS: at 89.64% examples, 91598 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:40:03,800 : INFO : PROGRESS: at 90.35% examples, 91611 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:40:04,800 : INFO : PROGRESS: at 91.05% examples, 91615 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:40:05,802 : INFO : PROGRESS: at 91.78% examples, 91629 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:40:06,803 : INFO : PROGRESS: at 92.48% examples, 91632 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:40:07,804 : INFO : PROGRESS: at 93.18% examples, 91638 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:40:08,806 : INFO : PROGRESS: at 93.90% examples, 91649 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:40:09,807 : INFO : PROGRESS: at 94.60% examples, 91657 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:40:10,809 : INFO : PROGRESS: at 95.31% examples, 91666 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:40:11,812 : INFO : PROGRESS: at 96.02% examples, 91674 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:40:12,812 : INFO : PROGRESS: at 96.73% examples, 91683 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:40:13,813 : INFO : PROGRESS: at 97.43% examples, 91689 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:40:14,813 : INFO : PROGRESS: at 98.14% examples, 91701 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:40:15,815 : INFO : PROGRESS: at 98.85% examples, 91702 words/s, in_qsize 1, out_qsize 0\n",
      "2018-01-24 18:40:16,815 : INFO : PROGRESS: at 99.55% examples, 91710 words/s, in_qsize 2, out_qsize 0\n",
      "2018-01-24 18:40:17,455 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-01-24 18:40:17,456 : INFO : training on 558798400 raw words (13097163 effective words) took 142.8s, 91712 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 28s, sys: 1.24 s, total: 2min 29s\n",
      "Wall time: 2min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13097163"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train doc2vec model\n",
    "%time model.train(train_docs, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-24 18:42:06,655 : INFO : saving Doc2Vec object under toy_data/model.bin, separately None\n",
      "2018-01-24 18:42:06,663 : INFO : not storing attribute syn0norm\n",
      "2018-01-24 18:42:06,670 : INFO : not storing attribute cum_table\n",
      "2018-01-24 18:42:06,811 : INFO : saved toy_data/model.bin\n"
     ]
    }
   ],
   "source": [
    "#save model\n",
    "model.save(saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
